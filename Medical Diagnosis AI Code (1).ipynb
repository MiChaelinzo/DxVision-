{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0332c638-0ef6-4060-beaa-639c07a9b3b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting tensorflow\n  Using cached tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\nCollecting pytorch\n  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: torchvision in /databricks/python3/lib/python3.10/site-packages (0.15.2+cpu)\nRequirement already satisfied: pydicom in /local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages (2.4.4)\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.10/site-packages (4.36.1)\nRequirement already satisfied: spacy in /databricks/python3/lib/python3.10/site-packages (3.7.2)\nRequirement already satisfied: lime in /local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages (0.2.0.1)\nRequirement already satisfied: shap in /databricks/python3/lib/python3.10/site-packages (0.44.0)\nRequirement already satisfied: libclang>=13.0.0 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (15.0.6.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (4.24.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nCollecting keras>=3.0.0\n  Using cached keras-3.3.3-py3-none-any.whl (1.1 MB)\nRequirement already satisfied: termcolor>=1.1.0 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (65.6.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nCollecting tensorboard<2.17,>=2.16\n  Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\nRequirement already satisfied: typing-extensions>=3.6.6 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (4.4.0)\nRequirement already satisfied: absl-py>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (1.0.0)\nRequirement already satisfied: astunparse>=1.6.0 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nCollecting h5py>=3.10.0\n  Using cached h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (1.48.2)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (23.2)\nRequirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\nCollecting ml-dtypes~=0.3.1\n  Using cached ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\nRequirement already satisfied: requests<3,>=2.21.0 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (2.28.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (1.23.5)\nRequirement already satisfied: flatbuffers>=23.5.26 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: wrapt>=1.11.0 in /databricks/python3/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.10/site-packages (from torchvision) (9.4.0)\nRequirement already satisfied: torch==2.0.1 in /databricks/python3/lib/python3.10/site-packages (from torchvision) (2.0.1+cpu)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1.2)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.9.0)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (1.11.1)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (2.8.4)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers) (2022.7.9)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: safetensors>=0.3.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /databricks/python3/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /databricks/python3/lib/python3.10/site-packages (from spacy) (5.2.1)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /databricks/python3/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (3.3.0)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /databricks/python3/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /databricks/python3/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /databricks/python3/lib/python3.10/site-packages (from spacy) (8.2.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /databricks/python3/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /databricks/python3/lib/python3.10/site-packages (from spacy) (1.10.6)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (0.9.0)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (0.3.4)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.10/site-packages (from lime) (1.10.0)\nRequirement already satisfied: scikit-image>=0.12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages (from lime) (0.23.2)\nRequirement already satisfied: matplotlib in /databricks/python3/lib/python3.10/site-packages (from lime) (3.7.0)\nRequirement already satisfied: scikit-learn>=0.18 in /databricks/python3/lib/python3.10/site-packages (from lime) (1.1.1)\nRequirement already satisfied: slicer==0.0.7 in /databricks/python3/lib/python3.10/site-packages (from shap) (0.0.7)\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.10/site-packages (from shap) (2.0.0)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from shap) (1.5.3)\nRequirement already satisfied: numba in /databricks/python3/lib/python3.10/site-packages (from shap) (0.56.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /databricks/python3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\nCollecting optree\n  Using cached optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\nCollecting rich\n  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\nCollecting namex\n  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\nRequirement already satisfied: imageio>=2.33 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages (from scikit-image>=0.12->lime) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages (from scikit-image>=0.12->lime) (2024.4.24)\nRequirement already satisfied: lazy-loader>=0.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages (from scikit-image>=0.12->lime) (0.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=0.18->lime) (2.2.0)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=0.18->lime) (1.2.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /databricks/python3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: markdown>=2.6.8 in /databricks/python3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.2)\nCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /databricks/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /databricks/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /databricks/python3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /databricks/python3/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.1)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (1.0.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (4.25.0)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (1.4.4)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /databricks/python3/lib/python3.10/site-packages (from numba->shap) (0.39.1)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->shap) (2022.7)\nCollecting pygments<3.0.0,>=2.13.0\n  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\nCollecting markdown-it-py>=2.2.0\n  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\nCollecting mdurl~=0.1\n  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nBuilding wheels for collected packages: pytorch\n  Building wheel for pytorch (setup.py): started\n  Building wheel for pytorch (setup.py): finished with status 'error'\n  error: subprocess-exited-with-error\n  \n  × python setup.py bdist_wheel did not run successfully.\n  │ exit code: 1\n  ╰─> [6 lines of output]\n      Traceback (most recent call last):\n        File \"<string>\", line 2, in <module>\n        File \"<pip-setuptools-caller>\", line 34, in <module>\n        File \"/tmp/pip-install-olagj8tn/pytorch_1f303b34507a469c8ebdd60fd92e890b/setup.py\", line 15, in <module>\n          raise Exception(message)\n      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\n  ERROR: Failed building wheel for pytorch\n  Running setup.py clean for pytorch\nFailed to build pytorch\nInstalling collected packages: pytorch, namex, pygments, protobuf, optree, ml-dtypes, mdurl, h5py, tensorboard, markdown-it-py, rich, keras, tensorflow\n  Running setup.py install for pytorch: started\n  Running setup.py install for pytorch: finished with status 'error'\n  error: subprocess-exited-with-error\n  \n  × Running setup.py install for pytorch did not run successfully.\n  │ exit code: 1\n  ╰─> [6 lines of output]\n      Traceback (most recent call last):\n        File \"<string>\", line 2, in <module>\n        File \"<pip-setuptools-caller>\", line 34, in <module>\n        File \"/tmp/pip-install-olagj8tn/pytorch_1f303b34507a469c8ebdd60fd92e890b/setup.py\", line 11, in <module>\n          raise Exception(message)\n      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: legacy-install-failure\n\n× Encountered error while trying to install package.\n╰─> pytorch\n\nnote: This is an issue with the package mentioned above, not pip.\nhint: See above for output from the failure.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2564373843470362>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Install necessary libraries\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpip\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minstall tensorflow pytorch torchvision pydicom transformers spacy lime shap\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2417\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n",
       "\u001B[1;32m   2415\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n",
       "\u001B[1;32m   2416\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n",
       "\u001B[0;32m-> 2417\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2419\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n",
       "\u001B[1;32m   2420\u001B[0m \u001B[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001B[39;00m\n",
       "\u001B[1;32m   2421\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n",
       "\u001B[1;32m   2422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/PipMagicOverrides.py:33\u001B[0m, in \u001B[0;36mPipMagicOverrides.pip\u001B[0;34m(self, line)\u001B[0m\n",
       "\u001B[1;32m     31\u001B[0m \u001B[38;5;129m@line_magic\u001B[39m\n",
       "\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpip\u001B[39m(\u001B[38;5;28mself\u001B[39m, line):\n",
       "\u001B[0;32m---> 33\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpipMagicHandler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunCmd\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpip\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/PipMagicOverrides.py:59\u001B[0m, in \u001B[0;36mPipMagicHandler.runCmd\u001B[0;34m(self, magicCmd, line)\u001B[0m\n",
       "\u001B[1;32m     57\u001B[0m     \u001B[38;5;28mprint\u001B[39m(PYTHON_RESTART_WARNING)\n",
       "\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsedResult\u001B[38;5;241m.\u001B[39mrewrittenCommand():\n",
       "\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecutePipCommand\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparsedResult\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     60\u001B[0m envManager\u001B[38;5;241m.\u001B[39mpostExecute(parsedResult)\n",
       "\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsedResult\u001B[38;5;241m.\u001B[39misMutation():\n",
       "\u001B[1;32m     62\u001B[0m     \u001B[38;5;66;03m# double print this output is at the end so it is more\u001B[39;00m\n",
       "\u001B[1;32m     63\u001B[0m     \u001B[38;5;66;03m# likely to be seen\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/PipMagicOverrides.py:118\u001B[0m, in \u001B[0;36mPipMagicHandler.executePipCommand\u001B[0;34m(self, result)\u001B[0m\n",
       "\u001B[1;32m    116\u001B[0m     sys\u001B[38;5;241m.\u001B[39mstdout\u001B[38;5;241m.\u001B[39mflush()\n",
       "\u001B[1;32m    117\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m returncode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[0;32m--> 118\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m subprocess\u001B[38;5;241m.\u001B[39mCalledProcessError(returncode, origCmd)\n",
       "\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m    120\u001B[0m     end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
       "\n",
       "\u001B[0;31mCalledProcessError\u001B[0m: Command 'pip --disable-pip-version-check install tensorflow pytorch torchvision pydicom transformers spacy lime shap' returned non-zero exit status 1."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "CalledProcessError",
        "evalue": "Command 'pip --disable-pip-version-check install tensorflow pytorch torchvision pydicom transformers spacy lime shap' returned non-zero exit status 1."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>CalledProcessError</span>: Command 'pip --disable-pip-version-check install tensorflow pytorch torchvision pydicom transformers spacy lime shap' returned non-zero exit status 1."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
        "File \u001B[0;32m<command-2564373843470362>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Install necessary libraries\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpip\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minstall tensorflow pytorch torchvision pydicom transformers spacy lime shap\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2417\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[1;32m   2415\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[1;32m   2416\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[0;32m-> 2417\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2419\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2420\u001B[0m \u001B[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2421\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
        "File \u001B[0;32m/databricks/python_shell/dbruntime/PipMagicOverrides.py:33\u001B[0m, in \u001B[0;36mPipMagicOverrides.pip\u001B[0;34m(self, line)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;129m@line_magic\u001B[39m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpip\u001B[39m(\u001B[38;5;28mself\u001B[39m, line):\n\u001B[0;32m---> 33\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpipMagicHandler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunCmd\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpip\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/databricks/python_shell/dbruntime/PipMagicOverrides.py:59\u001B[0m, in \u001B[0;36mPipMagicHandler.runCmd\u001B[0;34m(self, magicCmd, line)\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28mprint\u001B[39m(PYTHON_RESTART_WARNING)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsedResult\u001B[38;5;241m.\u001B[39mrewrittenCommand():\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecutePipCommand\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparsedResult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m envManager\u001B[38;5;241m.\u001B[39mpostExecute(parsedResult)\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsedResult\u001B[38;5;241m.\u001B[39misMutation():\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;66;03m# double print this output is at the end so it is more\u001B[39;00m\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;66;03m# likely to be seen\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python_shell/dbruntime/PipMagicOverrides.py:118\u001B[0m, in \u001B[0;36mPipMagicHandler.executePipCommand\u001B[0;34m(self, result)\u001B[0m\n\u001B[1;32m    116\u001B[0m     sys\u001B[38;5;241m.\u001B[39mstdout\u001B[38;5;241m.\u001B[39mflush()\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m returncode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 118\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m subprocess\u001B[38;5;241m.\u001B[39mCalledProcessError(returncode, origCmd)\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    120\u001B[0m     end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
        "\u001B[0;31mCalledProcessError\u001B[0m: Command 'pip --disable-pip-version-check install tensorflow pytorch torchvision pydicom transformers spacy lime shap' returned non-zero exit status 1."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "%pip install tensorflow pytorch torchvision pydicom transformers spacy lime shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "212091f6-c8d7-4af7-9ad3-61ed39325339",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting lime\n  Using cached lime-0.2.0.1-py3-none-any.whl\nCollecting scikit-image>=0.12\n  Using cached scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.10/site-packages (from lime) (1.10.0)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from lime) (1.23.5)\nRequirement already satisfied: scikit-learn>=0.18 in /databricks/python3/lib/python3.10/site-packages (from lime) (1.1.1)\nRequirement already satisfied: matplotlib in /databricks/python3/lib/python3.10/site-packages (from lime) (3.7.0)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from lime) (4.64.1)\nRequirement already satisfied: pillow>=9.1 in /databricks/python3/lib/python3.10/site-packages (from scikit-image>=0.12->lime) (9.4.0)\nCollecting lazy-loader>=0.4\n  Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\nRequirement already satisfied: packaging>=21 in /databricks/python3/lib/python3.10/site-packages (from scikit-image>=0.12->lime) (23.2)\nCollecting tifffile>=2022.8.12\n  Using cached tifffile-2024.4.24-py3-none-any.whl (225 kB)\nRequirement already satisfied: networkx>=2.8 in /databricks/python3/lib/python3.10/site-packages (from scikit-image>=0.12->lime) (2.8.4)\nCollecting imageio>=2.33\n  Using cached imageio-2.34.1-py3-none-any.whl (313 kB)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=0.18->lime) (2.2.0)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=0.18->lime) (1.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (1.0.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (3.0.9)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (4.25.0)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->lime) (1.4.4)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\nInstalling collected packages: tifffile, lazy-loader, imageio, scikit-image, lime\n  Attempting uninstall: lazy-loader\n    Found existing installation: lazy_loader 0.3\n    Not uninstalling lazy-loader at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374\n    Can't uninstall 'lazy_loader'. No files were found to uninstall.\nSuccessfully installed imageio-2.34.1 lazy-loader-0.4 lime-0.2.0.1 scikit-image-0.23.2 tifffile-2024.4.24\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd34fbab-a07c-494a-b972-a4a20ae9582d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3028, 3030)                                     UN: Array of 1251 elements\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages/pydicom/dataelem.py:847: UserWarning: Unknown DICOM tag (3028, 3030) - setting VR to 'UN'\n  warnings.warn(msg + \" - setting VR to 'UN'\")\n"
     ]
    }
   ],
   "source": [
    "print(dicom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d052d81-4998-4aed-a115-cae03945acc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2564373843470363>, line 16\u001B[0m\n",
       "\u001B[1;32m     14\u001B[0m image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(image_array)\n",
       "\u001B[1;32m     15\u001B[0m image \u001B[38;5;241m=\u001B[39m image\u001B[38;5;241m.\u001B[39mresize((\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m))  \u001B[38;5;66;03m# Assuming model input size\u001B[39;00m\n",
       "\u001B[0;32m---> 16\u001B[0m image_array \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(image) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.0\u001B[39m\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'np' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'np' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-2564373843470363>, line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(image_array)\n\u001B[1;32m     15\u001B[0m image \u001B[38;5;241m=\u001B[39m image\u001B[38;5;241m.\u001B[39mresize((\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m))  \u001B[38;5;66;03m# Assuming model input size\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m image_array \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(image) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.0\u001B[39m\n",
        "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d13410a-9722-438c-983c-dd7c993701f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "# Load patient data (assuming CSV format)\n",
    "patient_data = pd.read_csv(\"patient_data.csv\")\n",
    "\n",
    "# Load medical image (example with DICOM)\n",
    "image_path = \"1-001.dcm\"\n",
    "dicom_data = pydicom.dcmread(image_path, force=True)\n",
    "image_array = dicom_data.pixel_array\n",
    "\n",
    "# Preprocess image (resize, normalization)\n",
    "image = Image.fromarray(image_array)\n",
    "image = image.resize((224, 224))  # Assuming model input size\n",
    "image_array = np.array(image) / 255.0  # Normalize pixel values\n",
    "\n",
    "# ... further preprocessing based on data and model requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b33eb18f-53ee-4881-9223-3fd73bc9dd2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4426424200699463>, line 35\u001B[0m\n",
       "\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transforms\n",
       "\u001B[1;32m     34\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mRandomHorizontalFlip(p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)  \u001B[38;5;66;03m# 50% chance of flipping\u001B[39;00m\n",
       "\u001B[0;32m---> 35\u001B[0m augmented_image_array \u001B[38;5;241m=\u001B[39m transform(image_array)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n",
       "\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n",
       "\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n",
       "\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n",
       "\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n",
       "\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
       "\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torchvision/transforms/transforms.py:720\u001B[0m, in \u001B[0;36mRandomHorizontalFlip.forward\u001B[0;34m(self, img)\u001B[0m\n",
       "\u001B[1;32m    712\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    713\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n",
       "\u001B[1;32m    714\u001B[0m \u001B[38;5;124;03m    img (PIL Image or Tensor): Image to be flipped.\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    717\u001B[0m \u001B[38;5;124;03m    PIL Image or Tensor: Randomly flipped image.\u001B[39;00m\n",
       "\u001B[1;32m    718\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    719\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mp:\n",
       "\u001B[0;32m--> 720\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhflip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    721\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torchvision/transforms/functional.py:682\u001B[0m, in \u001B[0;36mhflip\u001B[0;34m(img)\u001B[0m\n",
       "\u001B[1;32m    680\u001B[0m     _log_api_usage_once(hflip)\n",
       "\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mTensor):\n",
       "\u001B[0;32m--> 682\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF_pil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhflip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    684\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F_t\u001B[38;5;241m.\u001B[39mhflip(img)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:54\u001B[0m, in \u001B[0;36mhflip\u001B[0;34m(img)\u001B[0m\n",
       "\u001B[1;32m     51\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39munused\n",
       "\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhflip\u001B[39m(img: Image\u001B[38;5;241m.\u001B[39mImage) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Image\u001B[38;5;241m.\u001B[39mImage:\n",
       "\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_pil_image(img):\n",
       "\u001B[0;32m---> 54\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg should be PIL Image. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(img)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\u001B[38;5;241m.\u001B[39mtranspose(Image\u001B[38;5;241m.\u001B[39mFLIP_LEFT_RIGHT)\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: img should be PIL Image. Got <class 'numpy.ndarray'>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "TypeError",
        "evalue": "img should be PIL Image. Got <class 'numpy.ndarray'>"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: img should be PIL Image. Got <class 'numpy.ndarray'>"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-4426424200699463>, line 35\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transforms\n\u001B[1;32m     34\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mRandomHorizontalFlip(p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)  \u001B[38;5;66;03m# 50% chance of flipping\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m augmented_image_array \u001B[38;5;241m=\u001B[39m transform(image_array)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torchvision/transforms/transforms.py:720\u001B[0m, in \u001B[0;36mRandomHorizontalFlip.forward\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m    712\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;124;03m    img (PIL Image or Tensor): Image to be flipped.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    717\u001B[0m \u001B[38;5;124;03m    PIL Image or Tensor: Randomly flipped image.\u001B[39;00m\n\u001B[1;32m    718\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    719\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mp:\n\u001B[0;32m--> 720\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhflip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    721\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torchvision/transforms/functional.py:682\u001B[0m, in \u001B[0;36mhflip\u001B[0;34m(img)\u001B[0m\n\u001B[1;32m    680\u001B[0m     _log_api_usage_once(hflip)\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m--> 682\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF_pil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhflip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    684\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F_t\u001B[38;5;241m.\u001B[39mhflip(img)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:54\u001B[0m, in \u001B[0;36mhflip\u001B[0;34m(img)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39munused\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhflip\u001B[39m(img: Image\u001B[38;5;241m.\u001B[39mImage) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Image\u001B[38;5;241m.\u001B[39mImage:\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_pil_image(img):\n\u001B[0;32m---> 54\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg should be PIL Image. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(img)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\u001B[38;5;241m.\u001B[39mtranspose(Image\u001B[38;5;241m.\u001B[39mFLIP_LEFT_RIGHT)\n",
        "\u001B[0;31mTypeError\u001B[0m: img should be PIL Image. Got <class 'numpy.ndarray'>"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "# Load patient data (assuming CSV format)\n",
    "patient_data = pd.read_csv(\"patient_data.csv\")\n",
    "\n",
    "# Load medical image (example with DICOM)\n",
    "image_path = \"1-001.dcm\"\n",
    "dicom_data = pydicom.dcmread(image_path, force=True)\n",
    "image_array = dicom_data.pixel_array\n",
    "\n",
    "# Preprocess image (resize, normalization)\n",
    "image = Image.fromarray(image_array)\n",
    "image = image.resize((224, 224))  # Assuming model input size\n",
    "image_array = np.array(image) / 255.0  # Normalize pixel values\n",
    "\n",
    "# --- Further Preprocessing Examples ---\n",
    "\n",
    "# 1. Standardization (subtract mean, divide by standard deviation)\n",
    "mean = np.mean(image_array)\n",
    "std = np.std(image_array)\n",
    "image_array = (image_array - mean) / std\n",
    "\n",
    "# 2. Contrast Enhancement (example with histogram equalization)\n",
    "from skimage import exposure\n",
    "\n",
    "image_array = exposure.equalize_hist(image_array)\n",
    "\n",
    "# 3. Data Augmentation (example with random flipping)\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.RandomHorizontalFlip(p=0.5)  # 50% chance of flipping\n",
    "augmented_image_array = transform(image_array)\n",
    "\n",
    "# ... add other preprocessing steps as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d70fa706-5d62-4ee3-87b6-a04e31549a05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/44128/command-2564373843470364-2840737832:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  image_data = np.array([[...], [...], ...])  # Replace with your actual image data\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2564373843470364>, line 20\u001B[0m\n",
       "\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Compile and train the model\u001B[39;00m\n",
       "\u001B[1;32m     19\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m\"\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\u001B[0;32m---> 20\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(image_data, labels, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
       "\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n",
       "\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n",
       "\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n",
       "\u001B[1;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n",
       "\u001B[1;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n",
       "\u001B[0;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-2564373843470364>, line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Compile and train the model\u001B[39;00m\n\u001B[1;32m     19\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m\"\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m---> 20\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(image_data, labels, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[1;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
        "\u001B[0;31mValueError\u001B[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the image data and labels (replace with your actual data)\n",
    "image_data = np.array(['56364408.dcm', '56364420.dcm', ...])  # 1D array of image file paths\n",
    "labels = np.array([0, 1, ...])  # Replace with your actual labels\n",
    "\n",
    "# Define a CNN model for image analysis (example)\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # ... additional layers\n",
    "    layers.Dense(1, activation=\"sigmoid\")  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(image_data, labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5b36283-6c0c-4458-a668-0d9141715661",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-151638418117575>, line 22\u001B[0m\n",
       "\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Compile and train the model\u001B[39;00m\n",
       "\u001B[1;32m     21\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
       "\u001B[0;32m---> 22\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(image_data, labels, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
       "\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n",
       "\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n",
       "\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1105\u001B[0m, in \u001B[0;36mselect_data_adapter\u001B[0;34m(x, y)\u001B[0m\n",
       "\u001B[1;32m   1102\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mcls\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m ALL_ADAPTER_CLS \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mcan_handle(x, y)]\n",
       "\u001B[1;32m   1103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m adapter_cls:\n",
       "\u001B[1;32m   1104\u001B[0m     \u001B[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001B[39;00m\n",
       "\u001B[0;32m-> 1105\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m   1106\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to find data adapter that can handle input: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n",
       "\u001B[1;32m   1107\u001B[0m             _type_name(x), _type_name(y)\n",
       "\u001B[1;32m   1108\u001B[0m         )\n",
       "\u001B[1;32m   1109\u001B[0m     )\n",
       "\u001B[1;32m   1110\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(adapter_cls) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
       "\u001B[1;32m   1111\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n",
       "\u001B[1;32m   1112\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData adapters should be mutually exclusive for \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1113\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhandling inputs. Found multiple adapters \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m to handle \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1114\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(adapter_cls, _type_name(x), _type_name(y))\n",
       "\u001B[1;32m   1115\u001B[0m     )\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: Failed to find data adapter that can handle input: <class 'tensorflow.python.framework.ops.EagerTensor'>, <class 'ellipsis'>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "Failed to find data adapter that can handle input: <class 'tensorflow.python.framework.ops.EagerTensor'>, <class 'ellipsis'>"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: Failed to find data adapter that can handle input: <class 'tensorflow.python.framework.ops.EagerTensor'>, <class 'ellipsis'>"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-151638418117575>, line 22\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Compile and train the model\u001B[39;00m\n\u001B[1;32m     21\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 22\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(image_data, labels, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1105\u001B[0m, in \u001B[0;36mselect_data_adapter\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m   1102\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mcls\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m ALL_ADAPTER_CLS \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mcan_handle(x, y)]\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m adapter_cls:\n\u001B[1;32m   1104\u001B[0m     \u001B[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001B[39;00m\n\u001B[0;32m-> 1105\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1106\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to find data adapter that can handle input: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1107\u001B[0m             _type_name(x), _type_name(y)\n\u001B[1;32m   1108\u001B[0m         )\n\u001B[1;32m   1109\u001B[0m     )\n\u001B[1;32m   1110\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(adapter_cls) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1111\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1112\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData adapters should be mutually exclusive for \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1113\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhandling inputs. Found multiple adapters \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m to handle \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1114\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001B[1;32m   1115\u001B[0m     )\n",
        "\u001B[0;31mValueError\u001B[0m: Failed to find data adapter that can handle input: <class 'tensorflow.python.framework.ops.EagerTensor'>, <class 'ellipsis'>"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "# Load and preprocess the image data\n",
    "image_file_paths = ['medical_image1.dcm', 'medical_image2.dcm', ...]  # List of image file paths\n",
    "image_data = []  # List to store preprocessed image data\n",
    "\n",
    "image_data = tf.stack(image_data)  # Convert image_data list to a TensorFlow tensor\n",
    "\n",
    "# Define a CNN model for image analysis\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # ... additional layers\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(image_data, labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5854a72f-0ab1-4f25-a9a0-fed8e9bb6175",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use the trained model for prediction\n",
    "prediction = model.predict(image_array.reshape(1, 224, 224, 3))\n",
    "\n",
    "# ... post-processing and interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb98ba8a-92f2-408e-a0c8-4374efea8e57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Blowfish has been deprecated\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb4f9a87dad46efbd9f4dd1841766bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 154ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 30ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 32ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 30ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 30ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 29ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 28ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 28ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 36ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 28ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 30ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 30ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 32ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 40ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 28ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 29ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 28ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 29ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 24ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 29ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 25ms/step\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2564373843470366>, line 7\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Explain model predictions using LIME (example)\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m explainer \u001B[38;5;241m=\u001B[39m lime\u001B[38;5;241m.\u001B[39mlime_image\u001B[38;5;241m.\u001B[39mLimeImageExplainer()\n",
       "\u001B[0;32m----> 7\u001B[0m explanation \u001B[38;5;241m=\u001B[39m explainer\u001B[38;5;241m.\u001B[39mexplain_instance(image_array, model\u001B[38;5;241m.\u001B[39mpredict)\n",
       "\u001B[1;32m      8\u001B[0m explanation\u001B[38;5;241m.\u001B[39mshow_in_notebook()\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages/lime/lime_image.py:216\u001B[0m, in \u001B[0;36mLimeImageExplainer.explain_instance\u001B[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001B[0m\n",
       "\u001B[1;32m    212\u001B[0m     ret_exp\u001B[38;5;241m.\u001B[39mtop_labels\u001B[38;5;241m.\u001B[39mreverse()\n",
       "\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m top:\n",
       "\u001B[1;32m    214\u001B[0m     (ret_exp\u001B[38;5;241m.\u001B[39mintercept[label],\n",
       "\u001B[1;32m    215\u001B[0m      ret_exp\u001B[38;5;241m.\u001B[39mlocal_exp[label],\n",
       "\u001B[0;32m--> 216\u001B[0m      ret_exp\u001B[38;5;241m.\u001B[39mscore, ret_exp\u001B[38;5;241m.\u001B[39mlocal_pred) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_instance_with_data\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret_exp\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages/lime/lime_base.py:183\u001B[0m, in \u001B[0;36mLimeBase.explain_instance_with_data\u001B[0;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[0m\n",
       "\u001B[1;32m    181\u001B[0m weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_fn(distances)\n",
       "\u001B[1;32m    182\u001B[0m labels_column \u001B[38;5;241m=\u001B[39m neighborhood_labels[:, label]\n",
       "\u001B[0;32m--> 183\u001B[0m used_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_selection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mneighborhood_data\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    184\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mlabels_column\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    185\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    186\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    187\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_regressor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    189\u001B[0m     model_regressor \u001B[38;5;241m=\u001B[39m Ridge(alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, fit_intercept\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m    190\u001B[0m                             random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages/lime/lime_base.py:134\u001B[0m, in \u001B[0;36mLimeBase.feature_selection\u001B[0;34m(self, data, labels, weights, num_features, method)\u001B[0m\n",
       "\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    133\u001B[0m     n_method \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhighest_weights\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
       "\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_selection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    135\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_method\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages/lime/lime_base.py:80\u001B[0m, in \u001B[0;36mLimeBase.feature_selection\u001B[0;34m(self, data, labels, weights, num_features, method)\u001B[0m\n",
       "\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhighest_weights\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
       "\u001B[1;32m     78\u001B[0m     clf \u001B[38;5;241m=\u001B[39m Ridge(alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, fit_intercept\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m     79\u001B[0m                 random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n",
       "\u001B[0;32m---> 80\u001B[0m     \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     82\u001B[0m     coef \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mcoef_\n",
       "\u001B[1;32m     83\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sp\u001B[38;5;241m.\u001B[39msparse\u001B[38;5;241m.\u001B[39missparse(data):\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patch_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m     28\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\u001B[0;32m---> 29\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     30\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1122\u001B[0m, in \u001B[0;36mRidge.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n",
       "\u001B[1;32m   1102\u001B[0m \u001B[38;5;124;03m\"\"\"Fit Ridge regression model.\u001B[39;00m\n",
       "\u001B[1;32m   1103\u001B[0m \n",
       "\u001B[1;32m   1104\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1119\u001B[0m \u001B[38;5;124;03m    Fitted estimator.\u001B[39;00m\n",
       "\u001B[1;32m   1120\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m   1121\u001B[0m _accept_sparse \u001B[38;5;241m=\u001B[39m _get_valid_accept_sparse(sparse\u001B[38;5;241m.\u001B[39missparse(X), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver)\n",
       "\u001B[0;32m-> 1122\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1124\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1125\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_accept_sparse\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat64\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1128\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1129\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(X, y, sample_weight\u001B[38;5;241m=\u001B[39msample_weight)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/base.py:596\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n",
       "\u001B[1;32m    594\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n",
       "\u001B[1;32m    595\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 596\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    597\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n",
       "\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/utils/validation.py:1090\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n",
       "\u001B[1;32m   1070\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m   1071\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1072\u001B[0m     )\n",
       "\u001B[1;32m   1074\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n",
       "\u001B[1;32m   1075\u001B[0m     X,\n",
       "\u001B[1;32m   1076\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1087\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m   1088\u001B[0m )\n",
       "\u001B[0;32m-> 1090\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43m_check_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulti_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_numeric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1092\u001B[0m check_consistent_length(X, y)\n",
       "\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X, y\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/utils/validation.py:1100\u001B[0m, in \u001B[0;36m_check_y\u001B[0;34m(y, multi_output, y_numeric, estimator)\u001B[0m\n",
       "\u001B[1;32m   1098\u001B[0m \u001B[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m   1099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m multi_output:\n",
       "\u001B[0;32m-> 1100\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1101\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1102\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1103\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1104\u001B[0m \u001B[43m        \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1105\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1106\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1107\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1109\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   1110\u001B[0m     estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/utils/validation.py:893\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n",
       "\u001B[1;32m    887\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    888\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    889\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    890\u001B[0m     )\n",
       "\u001B[1;32m    892\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nd \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m:\n",
       "\u001B[0;32m--> 893\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    894\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    895\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n",
       "\u001B[1;32m    896\u001B[0m     )\n",
       "\u001B[1;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n",
       "\u001B[1;32m    899\u001B[0m     _assert_all_finite(\n",
       "\u001B[1;32m    900\u001B[0m         array,\n",
       "\u001B[1;32m    901\u001B[0m         input_name\u001B[38;5;241m=\u001B[39minput_name,\n",
       "\u001B[1;32m    902\u001B[0m         estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n",
       "\u001B[1;32m    903\u001B[0m         allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    904\u001B[0m     )\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: Found array with dim 5. Ridge expected <= 2."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "Found array with dim 5. Ridge expected <= 2."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: Found array with dim 5. Ridge expected <= 2."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-2564373843470366>, line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Explain model predictions using LIME (example)\u001B[39;00m\n\u001B[1;32m      6\u001B[0m explainer \u001B[38;5;241m=\u001B[39m lime\u001B[38;5;241m.\u001B[39mlime_image\u001B[38;5;241m.\u001B[39mLimeImageExplainer()\n\u001B[0;32m----> 7\u001B[0m explanation \u001B[38;5;241m=\u001B[39m explainer\u001B[38;5;241m.\u001B[39mexplain_instance(image_array, model\u001B[38;5;241m.\u001B[39mpredict)\n\u001B[1;32m      8\u001B[0m explanation\u001B[38;5;241m.\u001B[39mshow_in_notebook()\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages/lime/lime_image.py:216\u001B[0m, in \u001B[0;36mLimeImageExplainer.explain_instance\u001B[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001B[0m\n\u001B[1;32m    212\u001B[0m     ret_exp\u001B[38;5;241m.\u001B[39mtop_labels\u001B[38;5;241m.\u001B[39mreverse()\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m top:\n\u001B[1;32m    214\u001B[0m     (ret_exp\u001B[38;5;241m.\u001B[39mintercept[label],\n\u001B[1;32m    215\u001B[0m      ret_exp\u001B[38;5;241m.\u001B[39mlocal_exp[label],\n\u001B[0;32m--> 216\u001B[0m      ret_exp\u001B[38;5;241m.\u001B[39mscore, ret_exp\u001B[38;5;241m.\u001B[39mlocal_pred) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_instance_with_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret_exp\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages/lime/lime_base.py:183\u001B[0m, in \u001B[0;36mLimeBase.explain_instance_with_data\u001B[0;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[0m\n\u001B[1;32m    181\u001B[0m weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_fn(distances)\n\u001B[1;32m    182\u001B[0m labels_column \u001B[38;5;241m=\u001B[39m neighborhood_labels[:, label]\n\u001B[0;32m--> 183\u001B[0m used_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_selection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mneighborhood_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mlabels_column\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_regressor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     model_regressor \u001B[38;5;241m=\u001B[39m Ridge(alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, fit_intercept\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    190\u001B[0m                             random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages/lime/lime_base.py:134\u001B[0m, in \u001B[0;36mLimeBase.feature_selection\u001B[0;34m(self, data, labels, weights, num_features, method)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    133\u001B[0m     n_method \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhighest_weights\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_selection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_method\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-18021307-8031-4ab3-bd8f-531555053374/lib/python3.10/site-packages/lime/lime_base.py:80\u001B[0m, in \u001B[0;36mLimeBase.feature_selection\u001B[0;34m(self, data, labels, weights, num_features, method)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhighest_weights\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     78\u001B[0m     clf \u001B[38;5;241m=\u001B[39m Ridge(alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, fit_intercept\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     79\u001B[0m                 random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n\u001B[0;32m---> 80\u001B[0m     \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m     coef \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mcoef_\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sp\u001B[38;5;241m.\u001B[39msparse\u001B[38;5;241m.\u001B[39missparse(data):\n",
        "File \u001B[0;32m/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patch_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     28\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1122\u001B[0m, in \u001B[0;36mRidge.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1102\u001B[0m \u001B[38;5;124;03m\"\"\"Fit Ridge regression model.\u001B[39;00m\n\u001B[1;32m   1103\u001B[0m \n\u001B[1;32m   1104\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1119\u001B[0m \u001B[38;5;124;03m    Fitted estimator.\u001B[39;00m\n\u001B[1;32m   1120\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1121\u001B[0m _accept_sparse \u001B[38;5;241m=\u001B[39m _get_valid_accept_sparse(sparse\u001B[38;5;241m.\u001B[39missparse(X), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver)\n\u001B[0;32m-> 1122\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1124\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1125\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_accept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat64\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1128\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1129\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(X, y, sample_weight\u001B[38;5;241m=\u001B[39msample_weight)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/base.py:596\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    594\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 596\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    597\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/utils/validation.py:1090\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1070\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1071\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1072\u001B[0m     )\n\u001B[1;32m   1074\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m   1075\u001B[0m     X,\n\u001B[1;32m   1076\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1087\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1088\u001B[0m )\n\u001B[0;32m-> 1090\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43m_check_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulti_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_numeric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1092\u001B[0m check_consistent_length(X, y)\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X, y\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/utils/validation.py:1100\u001B[0m, in \u001B[0;36m_check_y\u001B[0;34m(y, multi_output, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m multi_output:\n\u001B[0;32m-> 1100\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1101\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1102\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1104\u001B[0m \u001B[43m        \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1105\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1106\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1107\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1109\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1110\u001B[0m     estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/utils/validation.py:893\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    887\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    888\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    889\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    890\u001B[0m     )\n\u001B[1;32m    892\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nd \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[0;32m--> 893\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    894\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    895\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    896\u001B[0m     )\n\u001B[1;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m    899\u001B[0m     _assert_all_finite(\n\u001B[1;32m    900\u001B[0m         array,\n\u001B[1;32m    901\u001B[0m         input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[1;32m    902\u001B[0m         estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[1;32m    903\u001B[0m         allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    904\u001B[0m     )\n",
        "\u001B[0;31mValueError\u001B[0m: Found array with dim 5. Ridge expected <= 2."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lime\n",
    "import lime.lime_image\n",
    "import shap\n",
    "\n",
    "# Explain model predictions using LIME (example)\n",
    "explainer = lime.lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(image_array, model.predict)\n",
    "explanation.show_in_notebook()\n",
    "\n",
    "# Use SHAP for feature importance analysis\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adc1a5fb-117c-4485-a1eb-b6eb06762da1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Example augmentation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Apply transformations to images during training\n",
    "augmented_image = transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b369f8b9-9b16-4298-b9ca-cefe79785c8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2564373843470368>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GridSearchCV\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwrappers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscikit_learn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasClassifier\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Define the function to create the Keras model\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_model\u001B[39m(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m):\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m# Create your Keras model here\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# ...\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow.keras.wrappers'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ModuleNotFoundError",
        "evalue": "No module named 'tensorflow.keras.wrappers'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ModuleNotFoundError</span>: No module named 'tensorflow.keras.wrappers'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
        "File \u001B[0;32m<command-2564373843470368>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GridSearchCV\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwrappers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscikit_learn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasClassifier\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Define the function to create the Keras model\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_model\u001B[39m(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m):\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m# Create your Keras model here\u001B[39;00m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# ...\u001B[39;00m\n",
        "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow.keras.wrappers'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Define the function to create the Keras model\n",
    "def create_model(learning_rate=0.01, batch_size=32):\n",
    "    # Create your Keras model here\n",
    "    # ...\n",
    "    return model\n",
    "\n",
    "# Create the KerasClassifier object\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.001],\n",
    "    'batch_size': [32, 64],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(image_data, labels)\n",
    "\n",
    "# Best model and parameters\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c65922b9-02dd-4b80-b46c-69aec9c9d050",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "\u001B[0;31mTypeError\u001B[0m: float() argument must be a string or a real number, not 'list'\n",
       "\n",
       "The above exception was the direct cause of the following exception:\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2564373843470369>, line 5\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Create an ensemble of models\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m ensemble_model \u001B[38;5;241m=\u001B[39m RandomForestClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n",
       "\u001B[0;32m----> 5\u001B[0m ensemble_model\u001B[38;5;241m.\u001B[39mfit(image_data, labels)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patch_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m     28\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\u001B[0;32m---> 29\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     30\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:331\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(y):\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse multilabel-indicator for y is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m--> 331\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\n",
       "\u001B[1;32m    333\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    334\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    335\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/base.py:596\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n",
       "\u001B[1;32m    594\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n",
       "\u001B[1;32m    595\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 596\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    597\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n",
       "\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n",
       "\u001B[1;32m   1069\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n",
       "\u001B[1;32m   1070\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m   1071\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1072\u001B[0m     )\n",
       "\u001B[0;32m-> 1074\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1088\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1090\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n",
       "\u001B[1;32m   1092\u001B[0m check_consistent_length(X, y)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/utils/validation.py:856\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n",
       "\u001B[1;32m    854\u001B[0m         array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mastype(dtype, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m\"\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
       "\u001B[1;32m    855\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 856\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    857\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n",
       "\u001B[1;32m    858\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    859\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n",
       "\u001B[1;32m    860\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "setting an array element with a sequence."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: setting an array element with a sequence."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "\u001B[0;31mTypeError\u001B[0m: float() argument must be a string or a real number, not 'list'",
        "\nThe above exception was the direct cause of the following exception:\n",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-2564373843470369>, line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Create an ensemble of models\u001B[39;00m\n\u001B[1;32m      4\u001B[0m ensemble_model \u001B[38;5;241m=\u001B[39m RandomForestClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m ensemble_model\u001B[38;5;241m.\u001B[39mfit(image_data, labels)\n",
        "File \u001B[0;32m/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patch_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     28\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:331\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(y):\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse multilabel-indicator for y is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 331\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    335\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/base.py:596\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    594\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 596\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    597\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1069\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[1;32m   1070\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1071\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1072\u001B[0m     )\n\u001B[0;32m-> 1074\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1088\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1090\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m   1092\u001B[0m check_consistent_length(X, y)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sklearn/utils/validation.py:856\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    854\u001B[0m         array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mastype(dtype, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m\"\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 856\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[1;32m    858\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    859\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[1;32m    860\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
        "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create an ensemble of models\n",
    "ensemble_model = RandomForestClassifier(n_estimators=100)\n",
    "ensemble_model.fit(image_data, labels)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Medical Diagnosis AI Code",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
